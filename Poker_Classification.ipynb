{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "# Matplotlib \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# SciKitLearn is a machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.genfromtxt('poker-hand-training-true.data', delimiter=',',dtype=None)\n",
    "y = np.genfromtxt('poker-hand-testing.data', delimiter=',',dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 10  1 ...,  1  1  9]\n",
      " [ 2 11  2 ...,  2  1  9]\n",
      " [ 3 12  3 ...,  3  1  9]\n",
      " ..., \n",
      " [ 2  1  2 ...,  4 13  1]\n",
      " [ 2 12  4 ...,  4  9  1]\n",
      " [ 1  7  3 ...,  3  7  1]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 11)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = x[0:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9 9 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x[0:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 10  1 ..., 12  1  1]\n",
      " [ 2 11  2 ..., 12  2  1]\n",
      " [ 3 12  3 ..., 10  3  1]\n",
      " ..., \n",
      " [ 2  1  2 ...,  1  4 13]\n",
      " [ 2 12  4 ..., 12  4  9]\n",
      " [ 1  7  3 ...,  8  3  7]]\n",
      "(25010, 10)\n",
      "[[ 1  2  3 ...,  2  2  1]\n",
      " [10 11 12 ...,  1 12  7]\n",
      " [ 1  2  3 ...,  2  4  3]\n",
      " ..., \n",
      " [12 12 10 ...,  1 12  8]\n",
      " [ 1  2  3 ...,  4  4  3]\n",
      " [ 1  1  1 ..., 13  9  7]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train.reshape(x_train.shape[0], -1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3 ...,  2  2  1]\n",
      " [10 11 12 ...,  1 12  7]\n",
      " [ 1  2  3 ...,  2  4  3]\n",
      " ..., \n",
      " [12 12 10 ...,  1 12  8]\n",
      " [ 1  2  3 ...,  4  4  3]\n",
      " [ 1  1  1 ..., 13  9  7]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 13  2  4  2  3  1 12  0]\n"
     ]
    }
   ],
   "source": [
    "print (y[0])\n",
    "y_test = y[0:,10]\n",
    "x_test = y[0:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    X = tf.placeholder(tf.float32,shape=[n_x,None],name='X')\n",
    "    Y = tf.placeholder(tf.float32, shape=[n_y,None], name='Y')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 25010)\n",
      "(10, 1000000)\n"
     ]
    }
   ],
   "source": [
    "y_train_new = convert_to_one_hot(y_train,10)\n",
    "y_test_new = convert_to_one_hot(y_test,10)\n",
    "print(y_train_new.shape)\n",
    "print(y_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    W1 = tf.get_variable(\"W1\", [64,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable(\"b1\", [64, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [64,64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable(\"b2\", [64, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [10,64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.get_variable(\"b3\", [10, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)\n",
    "    A1 = tf.nn.tanh(Z1)\n",
    "    #A1 = tf.nn.dropout(A1, keep_prob = 0.99) #adding drop out for first layer with 0.98 probability.\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)\n",
    "    A2 = tf.nn.tanh(Z2)\n",
    "    #A2 = tf.nn.dropout(A2, keep_prob = 0.91)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y, parameters):\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    #using L2 regularization \n",
    "    Lambda=0.025\n",
    "    \n",
    "    cost_normal = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    l2_cost = Lambda*(tf.nn.l2_loss(parameters[\"W1\"]) + tf.nn.l2_loss(parameters[\"W2\"]) + tf.nn.l2_loss(parameters[\"W3\"]))\n",
    "    \n",
    "    cost = tf.add(cost_normal, l2_cost, name='cost')\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train,X_test, Y_test, learning_rate = 0.02,\n",
    "          num_epochs = 2500, minibatch_size = 32, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    \n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    #print(m)\n",
    "    \n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y , parameters)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(num_epochs):  \n",
    "            sess.run([optimizer,cost], feed_dict={X: X_train, Y: Y_train}) # Take a gradient descent step using our inputs and labels\n",
    "\n",
    "            # That's all! The rest of the cell just outputs debug messages. \n",
    "            # Display logs per epoch step\n",
    "            if (i) % 100 == 0:\n",
    "                cc = sess.run(cost, feed_dict={X: X_train, Y:Y_train})\n",
    "                print (\"Training step:\", '%04d' % (i), \"cost=\", \"{:.9f}\".format(cc) )#, \\\"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "            #if print_cost == True and num_epochs % 100 == 0:\n",
    "             #   print (\"Cost after epoch %i: %f\" % (num_epochs, cost))\n",
    "            if print_cost == True and num_epochs % 5 == 0:\n",
    "                costs.append(cc)\n",
    "                 \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        #print(classification_report(y_test,correct_prediction))\n",
    "        print(tf.confusion_matrix(y_test, correct_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step: 0000 cost= 2.348292828\n",
      "Training step: 0100 cost= 1.028177142\n",
      "Training step: 0200 cost= 1.012646675\n",
      "Training step: 0300 cost= 1.005935192\n",
      "Training step: 0400 cost= 1.001191139\n",
      "Training step: 0500 cost= 0.997490406\n",
      "Training step: 0600 cost= 0.994628131\n",
      "Training step: 0700 cost= 0.992526472\n",
      "Training step: 0800 cost= 0.990967929\n",
      "Training step: 0900 cost= 0.989800274\n",
      "Training step: 1000 cost= 0.988816857\n",
      "Training step: 1100 cost= 0.988072693\n",
      "Training step: 1200 cost= 0.988413036\n",
      "Training step: 1300 cost= 0.986989796\n",
      "Training step: 1400 cost= 0.987886429\n",
      "Training step: 1500 cost= 0.986332893\n",
      "Training step: 1600 cost= 0.986106515\n",
      "Training step: 1700 cost= 0.985995829\n",
      "Training step: 1800 cost= 0.985841453\n",
      "Training step: 1900 cost= 0.985673547\n",
      "Training step: 2000 cost= 0.985978305\n",
      "Training step: 2100 cost= 0.985605359\n",
      "Training step: 2200 cost= 0.985834002\n",
      "Training step: 2300 cost= 0.985748470\n",
      "Training step: 2400 cost= 0.985649526\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njEPBzMwyDgUzM8v8fxvgLxSGME7QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x163cbc0d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.49952\n",
      "Test Accuracy: 0.501209\n",
      "Tensor(\"confusion_matrix/SparseTensorDenseAdd:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "parameters = model(x_train.T, y_train_new, x_test.T, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
